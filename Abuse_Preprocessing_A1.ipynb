{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Abuse Preprocessing A1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9hMNAcjBHTK"
      },
      "source": [
        "## Here are the links to the publicly available datasets that I used:\n",
        "\n",
        "Hate Speech English Dataset: https://archive.ics.uci.edu/ml/machine-learning-databases/20newsgroups-mld/20_newsgroups.tar.gz\n",
        "\n",
        "Reddit Hate Speech Dataset: https://github.com/jing-qian/A-Benchmark-Dataset-for-Learning-to-Intervene-in-Online-Hate-Speech\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxTSKz9C2KcP"
      },
      "source": [
        "# Importing the libraries:\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv5aMuGDNirv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e780605a-01bd-4042-a39b-b1aa9f221ac7"
      },
      "source": [
        "# Reading the data:\n",
        "reddit = pd.read_csv(\"/content/drive/My Drive/Glue Labs/Data-Comments/reddit.csv\")\n",
        "reddit.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>hate_speech_idx</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1. e8q18lf\\n2. \\te8q9w5s\\n3. \\t\\te8qbobk\\n4. \\...</td>\n",
              "      <td>1. A subsection of retarded Hungarians? Ohh bo...</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[\"I don't see a reason why it's okay to insult...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1. e9c6naz\\n2. \\te9d03a5\\n3. \\t\\te9d8e4d\\n</td>\n",
              "      <td>1. &gt; \"y'all hear sumn?\"  by all means I live i...</td>\n",
              "      <td>[3]</td>\n",
              "      <td>['Persons with disabilities is the accepted te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1. e84rl2i\\n2. \\te84w60l\\n3. \\t\\te8544rn\\n4. \\...</td>\n",
              "      <td>1. wouldn't the defenders or whatever they are...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1. e7kq72n\\n2. \\te7m24ar\\n</td>\n",
              "      <td>1. Because the Japanese aren't retarded and kn...</td>\n",
              "      <td>[1]</td>\n",
              "      <td>[\"It's not right for anyone of any gender to b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1. e7hdgoh\\n2. \\te7iyj6a\\n3. \\t\\te7j6iho\\n4. \\...</td>\n",
              "      <td>1. That might be true if we didn't have an exa...</td>\n",
              "      <td>[2, 3]</td>\n",
              "      <td>[\"You shouldn't be bringing up sensitive topic...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  id  ...                                           response\n",
              "0  1. e8q18lf\\n2. \\te8q9w5s\\n3. \\t\\te8qbobk\\n4. \\...  ...  [\"I don't see a reason why it's okay to insult...\n",
              "1         1. e9c6naz\\n2. \\te9d03a5\\n3. \\t\\te9d8e4d\\n  ...  ['Persons with disabilities is the accepted te...\n",
              "2  1. e84rl2i\\n2. \\te84w60l\\n3. \\t\\te8544rn\\n4. \\...  ...                                                NaN\n",
              "3                         1. e7kq72n\\n2. \\te7m24ar\\n  ...  [\"It's not right for anyone of any gender to b...\n",
              "4  1. e7hdgoh\\n2. \\te7iyj6a\\n3. \\t\\te7j6iho\\n4. \\...  ...  [\"You shouldn't be bringing up sensitive topic...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukjHT9sAgH5m"
      },
      "source": [
        "# Dropping useless columns:\n",
        "reddit.drop(['id', 'response'], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vik7pZoX0P-I"
      },
      "source": [
        "Lets try to define a function that preprocesses a paragraph we pass through it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYkvNC9fSHjg"
      },
      "source": [
        "def preprocesstext(text):\n",
        "  u = text.replace(str(\"[deleted]\"), \"\")\n",
        "  v = u.replace(str(\"[removed]\"), \"\")\n",
        "  w = v.replace(str(\"[\"), \"\")\n",
        "  x = w.replace(str(\"]\"), \"\")\n",
        "  y = x.replace(str(\"*\"), \"\")\n",
        "  z = y.replace(str(\"/r/\"), \"\")\n",
        "  a = z.replace(str(\"/r/\"), \"\")\n",
        "  b = a.replace(str(\"/\"), \"\")\n",
        "  c = b.replace(str(\"\\t\"), \"\")\n",
        "  d = c.replace(str(\"\\n\"), \"\")\n",
        "  e = d.replace(str(1) + \".\", \"\")\n",
        "  f = e.replace(str(2) + \".\", \"\")\n",
        "  g = f.replace(str(3) + \".\", \"\")\n",
        "  h = g.replace(str(4) + \".\", \"\")\n",
        "  i = h.replace(str(5) + \".\", \"\")\n",
        "  j = i.replace(str(6) + \".\", \"\")\n",
        "  k = j.replace(str(\">\"), \"\")\n",
        "  l = k.replace(\"    \", \" \")\n",
        "  m = l.replace(\"   \", \" \")\n",
        "  n = m.replace(\"  \", \" \")\n",
        "  PreprocessedText = n\n",
        "  return PreprocessedText\n",
        "\n",
        "  # Not yet dealt with symbols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLneEbw8LhrV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "d034cf70-df62-45f0-bb87-8932006142a8"
      },
      "source": [
        "reddit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>hate_speech_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1. A subsection of retarded Hungarians? Ohh bo...</td>\n",
              "      <td>[1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1. &gt; \"y'all hear sumn?\"  by all means I live i...</td>\n",
              "      <td>[3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1. wouldn't the defenders or whatever they are...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1. Because the Japanese aren't retarded and kn...</td>\n",
              "      <td>[1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1. That might be true if we didn't have an exa...</td>\n",
              "      <td>[2, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5015</th>\n",
              "      <td>1. Who does she claim as *her people*?\\n2. \\tI...</td>\n",
              "      <td>[8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5016</th>\n",
              "      <td>1. Here's what's going to happen:  Broward is ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5017</th>\n",
              "      <td>1. Oh boy...so here comes a long venting post ...</td>\n",
              "      <td>[1, 4]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5018</th>\n",
              "      <td>1. OP, stop being a faggot and post videos nex...</td>\n",
              "      <td>[1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5019</th>\n",
              "      <td>1. In this 20 minute long video, Top Hate and ...</td>\n",
              "      <td>[2]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5020 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text hate_speech_idx\n",
              "0     1. A subsection of retarded Hungarians? Ohh bo...             [1]\n",
              "1     1. > \"y'all hear sumn?\"  by all means I live i...             [3]\n",
              "2     1. wouldn't the defenders or whatever they are...             NaN\n",
              "3     1. Because the Japanese aren't retarded and kn...             [1]\n",
              "4     1. That might be true if we didn't have an exa...          [2, 3]\n",
              "...                                                 ...             ...\n",
              "5015  1. Who does she claim as *her people*?\\n2. \\tI...             [8]\n",
              "5016  1. Here's what's going to happen:  Broward is ...             NaN\n",
              "5017  1. Oh boy...so here comes a long venting post ...          [1, 4]\n",
              "5018  1. OP, stop being a faggot and post videos nex...             [1]\n",
              "5019  1. In this 20 minute long video, Top Hate and ...             [2]\n",
              "\n",
              "[5020 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVKv7ywJ0GLB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ce777916-2d5f-44f8-9e93-e333ee1ef08a"
      },
      "source": [
        "# Lets take a look at this paragraph. \n",
        "reddit.text[5009]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1. What is it with girls in \"Pink\" shirts always being the cunt in the situation?\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmT6N8ohzpFZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4e8f6a4-5913-44c8-ef24-93377627dc48"
      },
      "source": [
        "# Now lets preprocess this:\n",
        "preprocesstext(reddit.text[5009])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' What is it with girls in \"Pink\" shirts always being the cunt in the situation?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9HSDZOn1DvG"
      },
      "source": [
        "Now, its time to preprocess the csv as a whole.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2vdzRORzxcE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "534a823f-3870-45bb-b857-74c8cf9da452"
      },
      "source": [
        "# Checking the dimensions of our csv:\n",
        "reddit.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5020, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ5WhkA-1LB7"
      },
      "source": [
        "for n in range(5020):\n",
        "  paragraph = reddit.text.iloc[n]\n",
        "  ProcessedParagraph = preprocesstext(paragraph)\n",
        "  reddit.text.iloc[n] = ProcessedParagraph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8ZZfYfUFBOB"
      },
      "source": [
        "reddit.columns = [\"text\", \"hatescore\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcW6gSWlAb9w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "95523b78-9dd5-4315-e527-f5ef149e092d"
      },
      "source": [
        "reddit[reddit['hatescore'].isnull()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>hatescore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wouldn't the defenders or whatever they are a...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Hate seeing inexperienced cops work, but man ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Grammatical errors, overt racism, child prost...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>“These are damaged, needy, lonely women,” say...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Sorry, I'm not following many news on America...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4987</th>\n",
              "      <td>Just stride in confidently with a \"sup fucker...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4989</th>\n",
              "      <td>how do these cunts keep a straight face while...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>As a father of a daughter who has been bullie...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5005</th>\n",
              "      <td>I said Gueten Tag to a German guy. It didn't ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5016</th>\n",
              "      <td>Here's what's going to happen: Broward is mag...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1173 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text hatescore\n",
              "2      wouldn't the defenders or whatever they are a...       NaN\n",
              "10     Hate seeing inexperienced cops work, but man ...       NaN\n",
              "17     Grammatical errors, overt racism, child prost...       NaN\n",
              "19     “These are damaged, needy, lonely women,” say...       NaN\n",
              "26     Sorry, I'm not following many news on America...       NaN\n",
              "...                                                 ...       ...\n",
              "4987   Just stride in confidently with a \"sup fucker...       NaN\n",
              "4989   how do these cunts keep a straight face while...       NaN\n",
              "4995   As a father of a daughter who has been bullie...       NaN\n",
              "5005   I said Gueten Tag to a German guy. It didn't ...       NaN\n",
              "5016   Here's what's going to happen: Broward is mag...       NaN\n",
              "\n",
              "[1173 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTHHp1BYPteu"
      },
      "source": [
        "We have NaN values which represent the clean tweets in there so lets replace them with a string [0]. We won't be using an integer since using a string which is similar to other values makes the preprocessing easier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRJIiChmF3YT"
      },
      "source": [
        "NullIndex = numpy.array((reddit[reddit['hatescore'].isnull()]).index)\n",
        "NullIndex = NullIndex.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0ueH2SrG9v6"
      },
      "source": [
        "for i in NullIndex:\n",
        "  reddit.hatescore.iloc[i] = str([0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry9dLdG1QSFo"
      },
      "source": [
        "Defining a getscore function which gets the hatescore:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPKzPE-C9w5M"
      },
      "source": [
        "def getscore(array):\n",
        "  \n",
        "  b = array.replace(\"[\", \"\").replace(\"]\", \"\").split(\", \")\n",
        "  \n",
        "  for i in range(len(b)):\n",
        "   b[i] = int(b[i])\n",
        "  \n",
        "  HateScore = sum(b)/len(b)\n",
        "  return HateScore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBlaqHmo_cIZ"
      },
      "source": [
        "for i in range(5020):\n",
        "  value = reddit.hatescore.iloc[i]\n",
        "  HateScore = getscore(value)\n",
        "  reddit.hatescore.iloc[i] = HateScore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5TrDseuAd2J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ddb3fca-d281-4189-83d1-5fc37cd65304"
      },
      "source": [
        "max(reddit.hatescore)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XhB5615QrAC"
      },
      "source": [
        "Finally lets make the all the hatescores above the value of 0 as value 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O9v6jS2Ak6j"
      },
      "source": [
        "HateTweetsIndex = (reddit[reddit[\"hatescore\"] > 0].index)\n",
        "HateTweetsIndex = HateTweetsIndex.tolist()\n",
        "\n",
        "for i in HateTweetsIndex:\n",
        "  reddit.hatescore.iloc[i] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ3FpL-KCEl2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "b667b54f-6c1a-4c2f-9af3-78db059d7f3f"
      },
      "source": [
        "reddit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>hatescore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A subsection of retarded Hungarians? Ohh boy....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"y'all hear sumn?\" by all means I live in a s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wouldn't the defenders or whatever they are a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Because the Japanese aren't retarded and know...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>That might be true if we didn't have an examp...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5015</th>\n",
              "      <td>Who does she claim as her people? I believe s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5016</th>\n",
              "      <td>Here's what's going to happen: Broward is mag...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5017</th>\n",
              "      <td>Oh boy...so here comes a long venting post an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5018</th>\n",
              "      <td>OP, stop being a faggot and post videos next ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5019</th>\n",
              "      <td>In this 20 minute long video, Top Hate and Ch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5020 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text hatescore\n",
              "0      A subsection of retarded Hungarians? Ohh boy....         1\n",
              "1      \"y'all hear sumn?\" by all means I live in a s...         1\n",
              "2      wouldn't the defenders or whatever they are a...         0\n",
              "3      Because the Japanese aren't retarded and know...         1\n",
              "4      That might be true if we didn't have an examp...         1\n",
              "...                                                 ...       ...\n",
              "5015   Who does she claim as her people? I believe s...         1\n",
              "5016   Here's what's going to happen: Broward is mag...         0\n",
              "5017   Oh boy...so here comes a long venting post an...         1\n",
              "5018   OP, stop being a faggot and post videos next ...         1\n",
              "5019   In this 20 minute long video, Top Hate and Ch...         1\n",
              "\n",
              "[5020 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF4-hIy8RPKd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "3de0f122-569a-4172-a0a2-9f76031f5c03"
      },
      "source": [
        "tweets = pd.read_csv(\"/content/drive/My Drive/Glue Labs/Data-Comments/Hate Speech English.csv\")\n",
        "tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24778</th>\n",
              "      <td>25291</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24779</th>\n",
              "      <td>25292</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24780</th>\n",
              "      <td>25294</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24781</th>\n",
              "      <td>25295</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>youu got wild bitches tellin you lies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24782</th>\n",
              "      <td>25296</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24783 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                              tweet\n",
              "0               0  ...  !!! RT @mayasolovely: As a woman you shouldn't...\n",
              "1               1  ...  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
              "2               2  ...  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
              "3               3  ...  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
              "4               4  ...  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
              "...           ...  ...                                                ...\n",
              "24778       25291  ...  you's a muthaf***in lie &#8220;@LifeAsKing: @2...\n",
              "24779       25292  ...  you've gone and broke the wrong heart baby, an...\n",
              "24780       25294  ...  young buck wanna eat!!.. dat nigguh like I ain...\n",
              "24781       25295  ...              youu got wild bitches tellin you lies\n",
              "24782       25296  ...  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...\n",
              "\n",
              "[24783 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ7mK6trnHKP"
      },
      "source": [
        "import re\n",
        "\n",
        "def PreprocessTweets(tweet):\n",
        "  n = re.sub(r'~', '', tweet)\n",
        "  o = re.sub(r'#', '', tweet)\n",
        "  p = re.sub(r'!+', '', o)\n",
        "  q = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'LINK', p)\n",
        "  r = re.sub(r'[*]', '', q)\n",
        "  s = re.sub(r'[@]\\w+', 'USER', r)\n",
        "  t = re.sub(r'[:|;]', '', s)\n",
        "  u = re.sub(r'[&]\\W+|\\d', '', t)\n",
        "  v = re.sub(r'[&]\\W+|\\d', '', u)\n",
        "  w = re.sub(r'[&]\\w+', '', v)\n",
        "  x = re.sub(r'    ', ' ', w)\n",
        "  y = re.sub(r'   ', ' ', x)\n",
        "  z = re.sub(r'  ', ' ', y)\n",
        "  ProcessedTweet = z \n",
        "  return ProcessedTweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_9Qs41rto49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd4ec4f2-17db-4cfb-efdd-83dae2ecea96"
      },
      "source": [
        "tweets.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24783, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vrmsgnrq225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "c2883bd4-868b-40ee-a5ce-bcc37dcfcdf4"
      },
      "source": [
        "for i in range(24783):\n",
        "  text = tweets['tweet'].iloc[i]\n",
        "  processedtweet = PreprocessTweets(text)\n",
        "  tweets['tweet'].iloc[i] = processedtweet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPfiAHr16XOA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "219de0e1-a912-464a-bf5e-998be214207c"
      },
      "source": [
        "for i in tweets.columns:\n",
        "  print(i, \",\", max(tweets[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unnamed: 0 , 25296\n",
            "count , 9\n",
            "hate_speech , 7\n",
            "offensive_language , 9\n",
            "neither , 9\n",
            "class , 2\n",
            "tweet , ~~Ruffled Ntac Eileen Dahlia - Beautiful color combination of pink, orange, yellow white. A Coll LINK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3OPiewRvs0H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64dd3c29-9ba3-4cdc-f15f-3e8acfb4f6bd"
      },
      "source": [
        "tweets.tweet[40]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\" momma said no pussy cats inside my doghouse \"'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py_S0s30wC6H"
      },
      "source": [
        "tweets.drop(['Unnamed: 0'], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MAjD4Jo3DG2"
      },
      "source": [
        "tweets['hatescore'] = 1.3*tweets['hate_speech'] + tweets['offensive_language'] - tweets['neither'] - 5*tweets['class'] / 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmKxMFPHALFz"
      },
      "source": [
        "OkayTweetsIndex = (tweets[tweets[\"hatescore\"] < 0].index).tolist()\n",
        "BadTweetsIndex = (tweets[tweets[\"hatescore\"] >= 0].index).tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufsD--u1AQrK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "d953f1af-8bdb-4f9b-d756-c93b590a7265"
      },
      "source": [
        "for i in OkayTweetsIndex:\n",
        "  tweets['hatescore'].iloc[i] = 0\n",
        "\n",
        "for i in BadTweetsIndex:\n",
        "  tweets['hatescore'].iloc[i] = 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02cYhbF-BdZm"
      },
      "source": [
        "tweets.drop(['count', 'hate_speech', 'offensive_language',\n",
        "             'neither', 'class'], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a2w1Z1tBtlJ"
      },
      "source": [
        "tweets.columns = reddit.columns\n",
        "tweets.index = range(0,24783)\n",
        "reddit.index = range(24783, 29803)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN364nAGEPpH"
      },
      "source": [
        "commentsdata = pd.concat([tweets, reddit])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb-CmkPCGMnm"
      },
      "source": [
        "bad = commentsdata[commentsdata['hatescore'] == 1].sample(n = 5000)\n",
        "good = commentsdata[commentsdata['hatescore'] == 0]\n",
        "newdata = pd.concat([bad, good])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47_HsmkUfC1P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "15fff7f3-be93-413f-9b24-62768fe7b583"
      },
      "source": [
        "pip install fastai --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2e/d4dcc69f67b4557c8543a4c65d3e136b1929b01136b227ceb986e2596825/fastai-2.0.15-py3-none-any.whl (185kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 4.8MB/s \n",
            "\u001b[?25hCollecting fastcore>=1.0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/76/4dcf007d76c93d0b4b987892ac5e1e4f0b43ec8a3cb1a367daa60e4043c5/fastcore-1.0.19-py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow in /usr/local/lib/python3.6/dist-packages (from fastai) (7.0.0)\n",
            "Requirement already satisfied, skipping upgrade: spacy in /usr/local/lib/python3.6/dist-packages (from fastai) (2.2.4)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from fastai) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from fastai) (1.6.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.6/dist-packages (from fastai) (19.3.1)\n",
            "Requirement already satisfied, skipping upgrade: torchvision>=0.7 in /usr/local/lib/python3.6/dist-packages (from fastai) (0.7.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from fastai) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from fastai) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from fastai) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from fastprogress>=0.2.4->fastai) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (1.1.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (50.3.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (2.0.3)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (3.0.2)\n",
            "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (7.4.0)\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->fastai) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastai) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai) (3.2.0)\n",
            "Installing collected packages: fastcore, fastai\n",
            "  Found existing installation: fastai 1.0.61\n",
            "    Uninstalling fastai-1.0.61:\n",
            "      Successfully uninstalled fastai-1.0.61\n",
            "Successfully installed fastai-2.0.15 fastcore-1.0.19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "fastai"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT6WntzMRYYm"
      },
      "source": [
        "commentsdata.to_csv(\"/content/drive/My Drive/Glue Labs/Data-Comments/Input/Input#1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZndHajEPS13"
      },
      "source": [
        "from fastai.text.all import *\n",
        "import pandas as pd\n",
        "import numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljFixGcsmNXk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "85b3388d-630f-4cf8-cf35-23bb046efca7"
      },
      "source": [
        "classifier = text_classifier_learner(dataloader, AWD_LSTM, metrics = accuracy).to_fp16()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hTuzK4BwzqY"
      },
      "source": [
        "def probabilty(text):\n",
        "  Class, tensorClass, probs = classifier.predict(text)\n",
        "  return print('the class is:', Class, \", with the probability of:\", float(max(numpy.array(probs)))*100, '%')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}