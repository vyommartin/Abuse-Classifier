{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing B2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F3r98G0P7jV"
      },
      "source": [
        "Whats different about this one?\n",
        "I basically clean the older Model 13 dataset again and remove all the stop words from the dataset. Crazy? I read somewhere that a cleaner dataset might help but I am afraid of what if this bad boy overfits? Okay, wait I have enough of it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGpSTiTOYAFS"
      },
      "source": [
        "# Importing Stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djGi5MBIX3_o",
        "outputId": "73d1e8db-0892-4229-d5a2-c4b4ba36eae3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohgtZM_oynXj"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmLkV5aM7Rz-"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdDy735I7R8j"
      },
      "source": [
        "import re\n",
        "\n",
        "def preprocess(text):\n",
        "  o = re.sub(r'\\\\', ' ', text)\n",
        "  k = re.sub(r'\\n', ' ', o)\n",
        "  l = re.sub(r'&', '', k)e\n",
        "  m = re.sub(r'RT ', '', l)\n",
        "  n = re.sub(r'~', '', m)\n",
        "  o = re.sub(r'#', '', n)\n",
        "  p = re.sub(r'!+', '', o)\n",
        "  q = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'link', p)\n",
        "  r = re.sub(r'[*]', '', q)\n",
        "  s = re.sub(r'[@]\\w+', 'user', r)\n",
        "  t = re.sub(r'[:|;]', '', s)\n",
        "  u = re.sub(r'[\\\\x]\\W+|\\d', '', t)\n",
        "  v = re.sub(r'[\\\\x]\\W+|\\d', '', u)\n",
        "  w = re.sub(r'[\\\\x]\\w+', '', v)\n",
        "  x = re.sub(r'    ', ' ', w)\n",
        "  y = re.sub(r'   ', ' ', x)\n",
        "  z = re.sub(r'  ', ' ', y)\n",
        "  ProcessedTweet = z.lower()\n",
        "  return ProcessedTweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11rzJVHbyqLZ"
      },
      "source": [
        "## Concat Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRnuJscLypuN"
      },
      "source": [
        "def concatexport(newdf, olddf, path):\n",
        "  df = pd.concat([olddf, newdf], axis = 0)\n",
        "  df = df.sample(n = df.shape[0])\n",
        "  df.index = range(df.shape[0])\n",
        "  df.to_csv(path)\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raqEP0lRP44T"
      },
      "source": [
        "## RemoveStopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7W-seDiP4cD"
      },
      "source": [
        "def removestopwords(text):\n",
        "\n",
        "  text_tokens = word_tokenize(text)\n",
        "\n",
        "  tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
        "\n",
        "  filtered_sentence = (\" \").join(tokens_without_sw)\n",
        "  return filtered_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXmCS3QgJ0KJ"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL2uyu7EJ2Ow"
      },
      "source": [
        "## Importing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDrSG-V_Jzsy"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Glue Labs/Abuse Model 13/input/input.csv\")\n",
        "data.drop(['Unnamed: 0'], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbLG5M1dKJSg"
      },
      "source": [
        "data = pd.concat([data['text'], data.isoffensive], axis=1)\n",
        "data.columns = ['text', 'labels']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3K_mNumKKID"
      },
      "source": [
        "yes = data[data.labels == 'Yes'].index\n",
        "for i in tqdm(yes):\n",
        "  data.labels.loc[i] = 1\n",
        "\n",
        "no = data[data.labels == 'No'].index\n",
        "for i in tqdm(no):\n",
        "  data.labels.loc[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3yVCi-CMPLu"
      },
      "source": [
        " ## Preprocessing Stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOCfbFmvNOdh"
      },
      "source": [
        "data.text.loc[1100:1140], data.text.loc[1111]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2WEP_N6Ojdp"
      },
      "source": [
        "def preprocessagain(text):\n",
        "  a = re.sub('[@_!#$+%^&*()<>?/\\|}{~:]', '', text)\n",
        "  b = re.sub('\"', \"\", a)\n",
        "  return b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vFKri5TfM8cF"
      },
      "source": [
        "for i in tqdm(data.index):\n",
        "  text = data.text.loc[i]\n",
        "  a = removestopwords(text)\n",
        "  data.text.loc[i] = a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGA3UJoTK92s"
      },
      "source": [
        "for i in tqdm(data.index):\n",
        "  try:\n",
        "    text = data.text.loc[i]\n",
        "    a = re.sub('[@_!#$+%^&*()<>?/\\|}{~:]', '', text)\n",
        "    b = re.sub('', \"\", a)\n",
        "    c = re.sub('\\'', \"\", b)\n",
        "    data.text.loc[i] = c\n",
        "  \n",
        "  except Exception:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24nC55EvFnIz"
      },
      "source": [
        "# Adding Data from Model 15"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPp3fSXoHQsD"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/Glue Labs/Abuse Model 16/Data/data.csv\")\n",
        "data.drop([\"Unnamed: 0\"], axis = 1, inplace = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_6jAeBFFnht"
      },
      "source": [
        "model15 = pd.read_csv(\"/content/drive/MyDrive/Glue Labs/Abuse Model 15/Data/data1.csv\")\n",
        "model15.drop([\"Unnamed: 0\"], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfarXjJEGltj"
      },
      "source": [
        "data1 = pd.concat([model15, data], axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSZzariJHwNr"
      },
      "source": [
        "data = data1.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "gre8p7CRICmu",
        "outputId": "635378ab-4069-4719-af5d-2edb5e2b5463"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pistola fuego cabeza yu ! piedad !</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sadism</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>w«í t«éo y√†n b√°i mi√†n fƒõn h√© b√°i t√°ng„ÄÇsh√¨ sƒÅn g√®...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id battre baise hors cul ‚Äô ‚Äô acteur</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‡ÆÆ‡Øá‡Æü‡ÆÆ‡Øç ‡ÆÖ‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡Æ§‡Æø ‡Æ∞‡Ææ‡ÆØ‡Øç ‡Æï‡Æ™‡Æø‡Æ≤‡Øç ‡Æ∑‡Æ∞‡Øç‡ÆÆ‡Ææ ‡Æ∑‡Øã ‡Æµ‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æ™‡Øã ,...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116182</th>\n",
              "      <td>how to gauge thoughtfulness vs creepyness</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116183</th>\n",
              "      <td>after 5 years my company is finally giving bac...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116184</th>\n",
              "      <td>user user user user omg itna gussa a ra hh is ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116185</th>\n",
              "      <td>gtlt ... usuario usuario bolas de mono de metal</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116186</th>\n",
              "      <td>user liebe \" pinselpoetin \" , m√§nner üòÇ ich sch...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>140368 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  labels\n",
              "0                      pistola fuego cabeza yu ! piedad !     0.0\n",
              "1                                                  sadism     1.0\n",
              "2       w«í t«éo y√†n b√°i mi√†n fƒõn h√© b√°i t√°ng„ÄÇsh√¨ sƒÅn g√®...     0.0\n",
              "3                     id battre baise hors cul ‚Äô ‚Äô acteur     0.0\n",
              "4       ‡ÆÆ‡Øá‡Æü‡ÆÆ‡Øç ‡ÆÖ‡Æ∞‡ØÅ‡Æ®‡Øç‡Æ§‡Æ§‡Æø ‡Æ∞‡Ææ‡ÆØ‡Øç ‡Æï‡Æ™‡Æø‡Æ≤‡Øç ‡Æ∑‡Æ∞‡Øç‡ÆÆ‡Ææ ‡Æ∑‡Øã ‡Æµ‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æ™‡Øã ,...     0.0\n",
              "...                                                   ...     ...\n",
              "116182          how to gauge thoughtfulness vs creepyness     0.0\n",
              "116183  after 5 years my company is finally giving bac...     0.0\n",
              "116184  user user user user omg itna gussa a ra hh is ...     1.0\n",
              "116185    gtlt ... usuario usuario bolas de mono de metal     1.0\n",
              "116186  user liebe \" pinselpoetin \" , m√§nner üòÇ ich sch...     0.0\n",
              "\n",
              "[140368 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz5qsNZ5FijN"
      },
      "source": [
        "# Compiling Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyI_dD0W34cL"
      },
      "source": [
        "data = data.sample(n = data.shape[0])\n",
        "data.index = range(data.shape[0])\n",
        "\n",
        "train = data.loc[:100000]\n",
        "test = data.loc[100000:]\n",
        "\n",
        "train.index = range(train.shape[0])\n",
        "test.index = range(test.shape[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBnxck0_Btln"
      },
      "source": [
        "data.to_csv(\"/content/drive/MyDrive/Glue Labs/Abuse Model 16/Data/data.csv\")\n",
        "train.to_csv(\"/content/drive/MyDrive/Glue Labs/Abuse Model 16/Data/train.csv\")\n",
        "test.to_csv(\"/content/drive/MyDrive/Glue Labs/Abuse Model 16/Data/test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMuqbVant2cf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCHoLwdmH79c"
      },
      "source": [
        "# Compiling Data1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLUyC4ZgH79c"
      },
      "source": [
        "data = data.sample(n = data.shape[0])\n",
        "data.index = range(data.shape[0])\n",
        "\n",
        "train = data.loc[:116000]\n",
        "test = data.loc[116000:]\n",
        "\n",
        "train.index = range(train.shape[0])\n",
        "test.index = range(test.shape[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_JqtfQ9H79d"
      },
      "source": [
        "data.to_csv(\"/content/drive/MyDrive/Glue Labs/Abuse Model 16/Data/data1.csv\")\n",
        "train.to_csv(\"/content/drive/MyDrive/Glue Labs/Abuse Model 16/Data/train1.csv\")\n",
        "test.to_csv(\"/content/drive/MyDrive/Glue Labs/Abuse Model 16/Data/test1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
